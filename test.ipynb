{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/qa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/qa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/qa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt');\n",
    "nltk.download('stopwords');\n",
    "nltk.download('averaged_perceptron_tagger');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"original_text.txt\", \"r\")\n",
    "text = f.read()\n",
    "sentences = sent_tokenize(text)\n",
    "total_documents = len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the Frequency matrix of the words in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "freq_matrix = _create_frequency_matrix(sentences);\n",
    "# print(freq_matrix);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate TermFrequency and generate a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "tf_matrix = _create_tf_matrix(freq_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating table for documents per words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "count_doc_per_words = _create_documents_per_words(freq_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate IDF and generate a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Calculate TF-IDF and generate a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Important Algorithm: score the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "sentence_scores = _score_sentences(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Find the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "threshold = _find_average_score(sentence_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Important Algorithm: Generate the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Have you experienced this before? Who is right and who is wrong? Neither. It was at that point their biggest breakthrough came. Perhaps all those years of perseverance finally paid off. It must come from within you. Where are you settling in your life right now? Could you be you playing for bigger stakes than you are? So become intentional on what you want out of life. Commit to it. Nurture your dreams.\n"
     ]
    }
   ],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary\n",
    "\n",
    "summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
    "print(summary);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, learning_curve, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('df_20.csv')\n",
    "df = pd.read_csv('df_9.csv')\n",
    "print(df.head());\n",
    "\n",
    "# 0 -> hate speech\n",
    "# 1 -> offensive language\n",
    "# 2 -> neither"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "1. Transform class column to binary classification: hate speech or not hate speech\n",
    "2. Remove stopwords, tweet handles/mentions and punctuation\n",
    "    - excludes [ 'rt' , '&#57361;' ]\n",
    "3. Lowercase and lemmatize words\n",
    "4. Use unigrams and bigrams\n",
    "5. Part-of-speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isHateSpeech'] = df['class'].map(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>isHateSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  isHateSpeech  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...             1  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...             1  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...             1  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...             1  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...             1  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english')\n",
    "excludes = ['rt', '&#57361;']\n",
    "all_stopwords.extend(excludes)\n",
    "\n",
    "def preprocess(tweet: str):\n",
    "    space_pattern = '\\s+'\n",
    "    url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "#     mention_regex = '@[\\w\\-]+'\n",
    "    mention_regex = '@[^\\s]+'\n",
    "    symbol_regex = '&#[^\\s]+'\n",
    "    \n",
    "    parsed_tweet = tweet.lower()\n",
    "    parsed_tweet = re.sub(space_pattern, ' ', parsed_tweet)\n",
    "    parsed_tweet = re.sub(url_regex, 'URLHERE', parsed_tweet)\n",
    "    parsed_tweet = re.sub(symbol_regex, ' ', parsed_tweet)\n",
    "    parsed_tweet = re.sub(mention_regex, 'MENTIONHERE', parsed_tweet)\n",
    "\n",
    "#     words = word_tokenize(parsed_tweet)\n",
    "    \n",
    "#     filtered_words = [word for word in words if not word in all_stopwords and word.isalnum()]\n",
    "#     porter = PorterStemmer()\n",
    "#     stemmed = [porter.stem(word) for word in filtered_words if word not in ['URLHERE', 'MENTIONHERE']]\n",
    "    \n",
    "#     pos = pos_tag(filtered_words)\n",
    "    \n",
    "    return parsed_tweet\n",
    "\n",
    "\n",
    "def stem_words(tweet: str):\n",
    "    words = word_tokenize(tweet)\n",
    "    filtered_words = [word for word in words if not word in all_stopwords and word.isalnum()]\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(word) for word in filtered_words if word not in ['URLHERE', 'MENTIONHERE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4]['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [woman, complain, clean, hous, amp, man, alway, take, trash]\n",
       "1    [boy, dat, cold, tyga, dwn, bad, cuffin, dat, hoe, 1st, place]\n",
       "2               [dawg, ever, fuck, bitch, start, cri, confus, shit]\n",
       "3                                              [look, like, tranni]\n",
       "4          [shit, hear, might, true, might, faker, bitch, told, ya]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "df.tweet.head().apply(preprocess).apply(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize data\n",
    "1. Bag of words model\n",
    "2. Term frequency/ Inverse document frequence (tf-idf)\n",
    "3. Normalize vectors to unit length\n",
    "\n",
    "Vectorizer\n",
    "- CountVectorizer\n",
    "- TfdifVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['isHateSpeech'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qa/Documents/Github/cs6220-data-mining/hate-speech-identifer/env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['could', 'might', 'must', 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# Define a count vectorizer\n",
    "count_vectorizer = CountVectorizer(\n",
    "    preprocessor=preprocess,\n",
    "    stop_words=all_stopwords,\n",
    "    tokenizer=stem_words)\n",
    "counts = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Define a tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocess,\n",
    "                                   tokenizer=stem_words, \n",
    "                                   ngram_range=(1,3), \n",
    "                                   stop_words=all_stopwords,\n",
    "                                   use_idf=True,\n",
    "                                   smooth_idf=False,\n",
    "                                   norm=None, #Applies l2 norm smoothing\n",
    "                                   decode_error='replace',\n",
    "                                   max_features=10000,\n",
    "                                   min_df=5,\n",
    "                                   max_df=0.501)\n",
    "tfidfs = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'well': 13698,\n",
       " 'els': 4358,\n",
       " 'white': 13792,\n",
       " 'ppl': 9914,\n",
       " 'get': 5415,\n",
       " 'us': 13271,\n",
       " 'forget': 5021,\n",
       " 'horrif': 6313,\n",
       " 'past': 9476,\n",
       " 'paint': 9394,\n",
       " 'pretti': 9967,\n",
       " 'pictur': 9674,\n",
       " 'ho': 6192,\n",
       " '8230': 738,\n",
       " 'funni': 5244,\n",
       " 'thing': 12555,\n",
       " 'peopl': 9566,\n",
       " 'see': 11071,\n",
       " 'pic': 9662,\n",
       " 'judg': 7019,\n",
       " 'bird': 1879,\n",
       " 'wrong': 14019,\n",
       " 'nigga': 8875,\n",
       " 'mess': 8241,\n",
       " 'bitch': 1898,\n",
       " '128557': 340,\n",
       " '128514': 298,\n",
       " 'ass': 1326,\n",
       " 'nigggaaa': 8889,\n",
       " 'real': 10343,\n",
       " 'speak': 11762,\n",
       " 'time': 12668,\n",
       " 'tryna': 12958,\n",
       " 'make': 7964,\n",
       " 'look': 7754,\n",
       " 'bad': 1506,\n",
       " 'like': 7599,\n",
       " 'eat': 4241,\n",
       " 'pussi': 10148,\n",
       " 'nah': 8680,\n",
       " 'mimi': 8338,\n",
       " 'basebal': 1624,\n",
       " 'season': 11053,\n",
       " 'win': 13874,\n",
       " 'yanke': 14107,\n",
       " 'love': 7808,\n",
       " 'start': 11910,\n",
       " 'alway': 1080,\n",
       " 'hatin': 5967,\n",
       " 'lmao': 7676,\n",
       " 'nude': 9039,\n",
       " 'call': 2479,\n",
       " 'would': 13998,\n",
       " 'rather': 10315,\n",
       " 'hey': 6107,\n",
       " 'girl': 5474,\n",
       " 'send': 11098,\n",
       " 'tit': 12687,\n",
       " 'hoe': 6198,\n",
       " 'babi': 1476,\n",
       " 'cook': 3217,\n",
       " 'bae': 1520,\n",
       " 'dinner': 3854,\n",
       " 'text': 12469,\n",
       " 'schedul': 10966,\n",
       " 'stay': 11923,\n",
       " 'home': 6237,\n",
       " 'fuck': 5174,\n",
       " 'u': 13074,\n",
       " 'okay': 9154,\n",
       " 'mani': 8003,\n",
       " 'realli': 10351,\n",
       " 'care': 2547,\n",
       " 'nip': 8918,\n",
       " 'shirt': 11252,\n",
       " 'beaner': 1680,\n",
       " 'drive': 4106,\n",
       " 'em': 4362,\n",
       " 'hahaha': 5836,\n",
       " 'dumb': 4169,\n",
       " 'understand': 13158,\n",
       " 'stop': 12004,\n",
       " 'vent': 13368,\n",
       " 'give': 5488,\n",
       " 'much': 8565,\n",
       " 'insight': 6668,\n",
       " 'life': 7582,\n",
       " 'amp': 1122,\n",
       " 'deserv': 3751,\n",
       " 'keep': 7115,\n",
       " 'talk': 12312,\n",
       " 'day': 3591,\n",
       " '128581': 359,\n",
       " '8220': 735,\n",
       " 'ham': 5884,\n",
       " 'face': 4616,\n",
       " '8221': 736,\n",
       " 'lilli': 7605,\n",
       " 'tri': 12890,\n",
       " 'climb': 2957,\n",
       " 'tree': 12877,\n",
       " 'complet': 3114,\n",
       " 'fail': 4639,\n",
       " 'oh': 9133,\n",
       " 'god': 5540,\n",
       " 'super': 12168,\n",
       " 'happen': 5918,\n",
       " 'citi': 2898,\n",
       " 'feel': 4749,\n",
       " 'need': 8771,\n",
       " 'shoot': 11282,\n",
       " 'shot': 11299,\n",
       " 'photo': 9653,\n",
       " 'main': 7953,\n",
       " 'yessssss': 14171,\n",
       " 'ladykimora': 7347,\n",
       " 'turntup': 13002,\n",
       " 'vega': 13350,\n",
       " '128525': 309,\n",
       " 'jordyn': 6996,\n",
       " 'fun': 5235,\n",
       " 'littl': 7655,\n",
       " 'dope': 4017,\n",
       " 'bag': 1522,\n",
       " 'side': 11346,\n",
       " 'never': 8809,\n",
       " 'let': 7527,\n",
       " 'turn': 12992,\n",
       " 'hous': 6337,\n",
       " 'wife': 13848,\n",
       " 'know': 7263,\n",
       " 'catch': 2598,\n",
       " 'fe': 4733,\n",
       " 'use': 13276,\n",
       " 'eggplant': 4301,\n",
       " 'emoji': 4380,\n",
       " 'refer': 10425,\n",
       " 'dick': 3807,\n",
       " 'purpl': 10138,\n",
       " 'green': 5688,\n",
       " 'top': 12767,\n",
       " 'doctor': 3949,\n",
       " 'bruh': 2271,\n",
       " 'red': 10399,\n",
       " 'bone': 2049,\n",
       " 'pusssi': 10149,\n",
       " 'hairlessss': 5861,\n",
       " 'hell': 6061,\n",
       " 'yea': 14137,\n",
       " 'ill': 6512,\n",
       " 'rep': 10498,\n",
       " 'fam': 4663,\n",
       " 'lol': 7730,\n",
       " 'betterwithpet': 1807,\n",
       " 'teamdonni': 12395,\n",
       " '128074': 194,\n",
       " 'nobodi': 8941,\n",
       " 'want': 13568,\n",
       " '25': 530,\n",
       " 'done': 3993,\n",
       " 'cod': 3024,\n",
       " 'yellow': 14161,\n",
       " 'rice': 10596,\n",
       " 'saut': 10921,\n",
       " '233': 520,\n",
       " 'ed': 4264,\n",
       " 'spinach': 11799,\n",
       " 'artichok': 1287,\n",
       " 'heart': 6016,\n",
       " 'made': 7926,\n",
       " 'clam': 2912,\n",
       " 'dat': 3576,\n",
       " 'nooki': 8977,\n",
       " 'pop': 9851,\n",
       " 'cooki': 3218,\n",
       " 'jar': 6861,\n",
       " 'ai': 978,\n",
       " 'rooki': 10729,\n",
       " 'girllll': 5482,\n",
       " 'yo': 14183,\n",
       " 'break': 2188,\n",
       " 'anoth': 1178,\n",
       " 'gone': 5571,\n",
       " 'good': 5577,\n",
       " 'guy': 5799,\n",
       " 'kick': 7178,\n",
       " 'long': 7743,\n",
       " 'hair': 5857,\n",
       " 'faggot': 4636,\n",
       " 'lil': 7604,\n",
       " 'video': 13410,\n",
       " 'game': 5312,\n",
       " 'team': 12394,\n",
       " 'nice': 8850,\n",
       " 'everyon': 4530,\n",
       " 'smile': 11563,\n",
       " 'confus': 3158,\n",
       " 'nanosecond': 8702,\n",
       " 'singlebecaus': 11396,\n",
       " 'find': 4833,\n",
       " 'cute': 3481,\n",
       " 'hoosier': 6292,\n",
       " 'date': 3578,\n",
       " 'next': 8834,\n",
       " 'year': 14145,\n",
       " '128527': 311,\n",
       " 'eddi': 4270,\n",
       " 'mistak': 8380,\n",
       " 'doe': 3955,\n",
       " 'car': 2539,\n",
       " 'smell': 11557,\n",
       " 'sweet': 12230,\n",
       " 'potato': 9893,\n",
       " 'bomb': 2043,\n",
       " 'shit': 11254,\n",
       " 'got': 5614,\n",
       " 'everi': 4519,\n",
       " 'weak': 13635,\n",
       " 'mean': 8156,\n",
       " 'someth': 11672,\n",
       " 'contrari': 3199,\n",
       " 'belief': 1740,\n",
       " 'queer': 10187,\n",
       " '8217': 734,\n",
       " 'go': 5530,\n",
       " 'around': 1274,\n",
       " 'offend': 9120,\n",
       " 'cishetero': 2895,\n",
       " 'say': 10935,\n",
       " 'darn': 3568,\n",
       " 'mac': 7906,\n",
       " '10': 6,\n",
       " 'lay': 7431,\n",
       " 'floor': 4946,\n",
       " 'matress': 8100,\n",
       " 'young': 14212,\n",
       " 'base': 1623,\n",
       " 'came': 2490,\n",
       " 'straight': 12024,\n",
       " 'cant': 2520,\n",
       " 'stand': 11892,\n",
       " 'especi': 4484,\n",
       " 'whini': 13782,\n",
       " 'even': 4514,\n",
       " 'scare': 10955,\n",
       " 'ca': 2444,\n",
       " 'neva': 8806,\n",
       " 'sucka': 12118,\n",
       " 'big': 1844,\n",
       " 'boob': 2059,\n",
       " 'ugli': 13094,\n",
       " 'short': 11292,\n",
       " 'rabchenko': 10218,\n",
       " 'ladi': 7345,\n",
       " 'wan': 13561,\n",
       " 'na': 8660,\n",
       " 'parti': 9460,\n",
       " 'weekend': 13674,\n",
       " 'basic': 1629,\n",
       " 'shop': 11286,\n",
       " 'hate': 5963,\n",
       " 'lt': 7837,\n",
       " '3': 574,\n",
       " 'ya': 14084,\n",
       " 'strap': 12031,\n",
       " 'full': 5230,\n",
       " 'retard': 10550,\n",
       " 'unblock': 13134,\n",
       " 'becom': 1698,\n",
       " 'man': 7987,\n",
       " 'wo': 13933,\n",
       " 'wit': 13907,\n",
       " 'sammich': 10874,\n",
       " 'ronni': 10724,\n",
       " 'radk': 10238,\n",
       " 'fag': 4632,\n",
       " 'fronz': 5146,\n",
       " 'sour': 11728,\n",
       " 'cream': 3346,\n",
       " 'onion': 9197,\n",
       " 'bobbi': 2021,\n",
       " 'could': 3271,\n",
       " 'someon': 11671,\n",
       " 'teeth': 12423,\n",
       " '128567': 350,\n",
       " 'mad': 7918,\n",
       " 'caus': 2610,\n",
       " 'wifey': 13850,\n",
       " 'think': 12563,\n",
       " 'ex': 4547,\n",
       " 'sick': 11342,\n",
       " 'suppos': 12185,\n",
       " 'hang': 5907,\n",
       " 'w': 13508,\n",
       " 'week': 13673,\n",
       " 'nigger': 8885,\n",
       " 'bump': 2353,\n",
       " 'file': 4819,\n",
       " 'sexual': 11153,\n",
       " 'harass': 5932,\n",
       " 'work': 13973,\n",
       " 'aint': 987,\n",
       " 'shook': 11280,\n",
       " 'swear': 12223,\n",
       " 'worri': 13988,\n",
       " 'noth': 9007,\n",
       " 'radar': 10232,\n",
       " 'gay': 5354,\n",
       " '127383': 87,\n",
       " 'take': 12299,\n",
       " 'tell': 12431,\n",
       " 'pass': 9471,\n",
       " 'insecur': 6661,\n",
       " 'moyl': 8550,\n",
       " 'fellani': 4758,\n",
       " 'instead': 6678,\n",
       " 'ae': 913,\n",
       " 'rvp': 10815,\n",
       " 'pleas': 9773,\n",
       " 'come': 3071,\n",
       " 'back': 1489,\n",
       " 'fergi': 4777,\n",
       " 'siralexferguson': 11404,\n",
       " 'manchesterunit': 7992,\n",
       " 'manchesterderbi': 7991,\n",
       " 'mufc': 8569,\n",
       " 'everybodi': 4523,\n",
       " 'hype': 6426,\n",
       " 'famou': 4667,\n",
       " 'nake': 8692,\n",
       " 'alik': 1030,\n",
       " 'money': 8452,\n",
       " 'wish': 13903,\n",
       " 'born': 2097,\n",
       " 'differ': 3828,\n",
       " 'gener': 5392,\n",
       " 'yall': 14103,\n",
       " 'hurt': 6410,\n",
       " 'sicken': 11343,\n",
       " 'children': 2785,\n",
       " 'tuck': 12972,\n",
       " 'ignor': 6487,\n",
       " 'mother': 8519,\n",
       " 'fucker': 5185,\n",
       " 'thirsti': 12573,\n",
       " '128129': 227,\n",
       " 'follow': 4987,\n",
       " 'ah': 956,\n",
       " 'ig': 6480,\n",
       " 'tho': 12578,\n",
       " '1inkkofrosess': 476,\n",
       " 'gon': 5568,\n",
       " 'tag': 12291,\n",
       " 'quit': 10207,\n",
       " 'hold': 6212,\n",
       " 'air': 989,\n",
       " 'dumbass': 4170,\n",
       " 'food': 4994,\n",
       " 'hot': 6326,\n",
       " 'breath': 2194,\n",
       " 'dragon': 4064,\n",
       " 'handl': 5901,\n",
       " 'iowa': 6738,\n",
       " 'kitti': 7233,\n",
       " 'joke': 6986,\n",
       " 'oleand': 9171,\n",
       " 'son': 11679,\n",
       " 'ron': 10720,\n",
       " 'ye': 14136,\n",
       " 'book': 2064,\n",
       " 'obersturmfuhr': 9087,\n",
       " 'matthia': 8104,\n",
       " 'superb': 12169,\n",
       " 'financi': 4832,\n",
       " 'brian': 2206,\n",
       " 'carri': 2568,\n",
       " 'label': 7336,\n",
       " 'presenc': 9957,\n",
       " 'fan': 4669,\n",
       " 'codi': 3027,\n",
       " 'zeller': 14276,\n",
       " 'nomin': 8964,\n",
       " 'nba': 8748,\n",
       " 'draft': 4061,\n",
       " 'iubb': 6799,\n",
       " 'homo': 6254,\n",
       " 'cracker': 3318,\n",
       " 'right': 10620,\n",
       " 'heard': 6015,\n",
       " 'one': 9194,\n",
       " 'obama': 9085,\n",
       " 'fli': 4927,\n",
       " 'tweet': 13020,\n",
       " 'worthless': 13997,\n",
       " 'teabagg': 12390,\n",
       " 'scum': 11039,\n",
       " 'peyton': 9623,\n",
       " 'remark': 10482,\n",
       " '8226': 737,\n",
       " 'yd': 14135,\n",
       " 'nfl': 8839,\n",
       " 'record': 10395,\n",
       " '55': 653,\n",
       " 'td': 12381,\n",
       " '450': 624,\n",
       " 'phone': 9648,\n",
       " 'cunt': 3448,\n",
       " 'whore': 13826,\n",
       " 'fart': 4692,\n",
       " 'holdin': 6214,\n",
       " 'sinc': 11386,\n",
       " '5th': 682,\n",
       " 'grade': 5640,\n",
       " 'handsom': 5906,\n",
       " 'buff': 2317,\n",
       " 'thang': 12484,\n",
       " 'last': 7397,\n",
       " 'night': 8899,\n",
       " 'ego': 4303,\n",
       " 'temporarili': 12440,\n",
       " 'elev': 4336,\n",
       " 'die': 3818,\n",
       " 'ask': 1317,\n",
       " 'tf': 12473,\n",
       " 'sad': 10831,\n",
       " 'nig': 8867,\n",
       " 'hover': 6342,\n",
       " 'parent': 9443,\n",
       " 'depend': 3729,\n",
       " 'stfu': 11969,\n",
       " 'amanda': 1085,\n",
       " 'ran': 10274,\n",
       " 'away': 1427,\n",
       " 'yeah': 14141,\n",
       " 'dream': 4083,\n",
       " 'ewwww': 4545,\n",
       " 'must': 8616,\n",
       " 'elza': 4361,\n",
       " 'jone': 6991,\n",
       " 'whipppppppen': 13786,\n",
       " 'drift': 4094,\n",
       " 'tu': 12967,\n",
       " 'niggah': 8880,\n",
       " 'famili': 4665,\n",
       " 'eye': 4600,\n",
       " 'n': 8659,\n",
       " 'rite': 10650,\n",
       " 'color': 3060,\n",
       " 'amish': 1114,\n",
       " 'rockin': 10691,\n",
       " 'gucci': 5760,\n",
       " 'smokin': 11573,\n",
       " 'smh': 11562,\n",
       " 'fake': 4648,\n",
       " 'bish': 1895,\n",
       " 'cutler': 3485,\n",
       " 'step': 11945,\n",
       " 'throw': 12608,\n",
       " 'threw': 12602,\n",
       " 'int': 6685,\n",
       " 'flat': 4905,\n",
       " 'foot': 5000,\n",
       " 'miss': 8371,\n",
       " '128532': 316,\n",
       " 'brrr': 2268,\n",
       " 'dichter': 3806,\n",
       " 'bij': 1859,\n",
       " 'het': 6103,\n",
       " 'sint': 11399,\n",
       " 'gebeuren': 5373,\n",
       " 'racistisch': 10229,\n",
       " 'de': 3605,\n",
       " 'drek': 4088,\n",
       " 'op': 9228,\n",
       " 'twitter': 13045,\n",
       " 'en': 4391,\n",
       " 'komt': 7285,\n",
       " 'nagenoeg': 8679,\n",
       " 'alleen': 1035,\n",
       " 'van': 13327,\n",
       " 'prozwartepieten': 10076,\n",
       " 'hoek': 6201,\n",
       " 'engvolk': 4414,\n",
       " 'relat': 10465,\n",
       " 'jesu': 6916,\n",
       " 'gpa': 5633,\n",
       " 'legaci': 7486,\n",
       " 'cheesi': 2754,\n",
       " 'bread': 2187,\n",
       " 'browni': 2265,\n",
       " '128523': 307,\n",
       " 'sorri': 11708,\n",
       " 'woman': 13947,\n",
       " 'help': 6075,\n",
       " 'unless': 13201,\n",
       " 'happycolumbusday': 5926,\n",
       " 'sound': 11724,\n",
       " 'peta': 9615,\n",
       " 'callou': 2482,\n",
       " 'buffalo': 2318,\n",
       " 'lot': 7789,\n",
       " 'wors': 13990,\n",
       " 'injun': 6643,\n",
       " 'soft': 11649,\n",
       " 'act': 869,\n",
       " 'tough': 12794,\n",
       " 'sit': 11410,\n",
       " 'watch': 13601,\n",
       " 'sidelin': 11349,\n",
       " 'entir': 4432,\n",
       " 'relationship': 10466,\n",
       " 'happi': 5920,\n",
       " 'thegoodlif': 12510,\n",
       " 'congrat': 3161,\n",
       " 'derek': 3741,\n",
       " 'jeter': 6919,\n",
       " 'shortstop': 11297,\n",
       " '14th': 400,\n",
       " 'final': 4830,\n",
       " 'farewellcaptain': 4687,\n",
       " 'charg': 2710,\n",
       " 'juvenil': 7056,\n",
       " 'michaelbrown': 8280,\n",
       " 'thug': 12617,\n",
       " 'point': 9806,\n",
       " 'cuz': 3488,\n",
       " 'live': 7661,\n",
       " 'half': 5871,\n",
       " 'shell': 11226,\n",
       " 'deep': 3653,\n",
       " 'fri': 5123,\n",
       " 'neck': 8767,\n",
       " 'colt': 3064,\n",
       " 'nation': 8727,\n",
       " 'put': 10151,\n",
       " 'chuassup': 2855,\n",
       " '24': 522,\n",
       " 'late': 7402,\n",
       " 'upload': 13246,\n",
       " 'trash': 12849,\n",
       " 'goodnight': 5582,\n",
       " 'number': 9049,\n",
       " 'colleg': 3051,\n",
       " 'republican': 10515,\n",
       " 'jail': 6836,\n",
       " 'treason': 12870,\n",
       " 'ju': 7016,\n",
       " 'faith': 4645,\n",
       " 'cu': 3428,\n",
       " 'kno': 7253,\n",
       " '128553': 336,\n",
       " '128128': 226,\n",
       " 'crook': 3388,\n",
       " 'shut': 11327,\n",
       " 'frame': 5066,\n",
       " 'suzan': 12206,\n",
       " 'sofa': 11648,\n",
       " 'damn': 3531,\n",
       " 'silverwar': 11372,\n",
       " 'golli': 5567,\n",
       " 'old': 9164,\n",
       " 'hahahaha': 5841,\n",
       " 'move': 8542,\n",
       " 'wayyyee': 13622,\n",
       " 'kid': 7183,\n",
       " 'definit': 3671,\n",
       " 'femal': 4766,\n",
       " 'complain': 3112,\n",
       " 'flaw': 4910,\n",
       " 'second': 11061,\n",
       " 'aeropostal': 915,\n",
       " 'wtf': 14024,\n",
       " 'friend': 5128,\n",
       " 'trynna': 12959,\n",
       " 'thot': 12586,\n",
       " '128166': 257,\n",
       " '128049': 181,\n",
       " 'smart': 11547,\n",
       " 'mouth': 8538,\n",
       " '128068': 188,\n",
       " '128069': 189,\n",
       " 'crazi': 3337,\n",
       " 'attitud': 1379,\n",
       " '128530': 314,\n",
       " '128175': 265,\n",
       " 'im': 6526,\n",
       " 'roethlisberg': 10699,\n",
       " 'expung': 4588,\n",
       " 'becam': 1696,\n",
       " 'drunk': 4134,\n",
       " 'bout': 2125,\n",
       " 'ride': 10610,\n",
       " 'poli': 9817,\n",
       " 'ratchet': 10310,\n",
       " 'loud': 7797,\n",
       " 'annoy': 1172,\n",
       " 'peek': 9544,\n",
       " 'boo': 2058,\n",
       " 'swag': 12211,\n",
       " 'tyga': 13057,\n",
       " 'worst': 13992,\n",
       " 'bar': 1593,\n",
       " 'tygabar': 13058,\n",
       " 'took': 12754,\n",
       " 'hit': 6174,\n",
       " 'high': 6128,\n",
       " 'shoutout': 11307,\n",
       " 'brooklyn': 2251,\n",
       " 'ga': 5281,\n",
       " 'way': 13617,\n",
       " 'atlant': 1362,\n",
       " 'ghetto': 5438,\n",
       " 'target': 12347,\n",
       " '85': 745,\n",
       " 'speci': 11766,\n",
       " 'report': 10505,\n",
       " 'chesterfield': 2766,\n",
       " 'great': 5680,\n",
       " 'backyard': 1504,\n",
       " 'count': 3277,\n",
       " 'area': 1251,\n",
       " 'fault': 4714,\n",
       " 'everyday': 4526,\n",
       " 'virgo': 13445,\n",
       " 'ta': 12277,\n",
       " 'chill': 2788,\n",
       " 'beyonc': 1816,\n",
       " '232': 519,\n",
       " 'beat': 1687,\n",
       " '128076': 196,\n",
       " 'slap': 11468,\n",
       " 'asshol': 1331,\n",
       " 'chair': 2680,\n",
       " 'favorit': 4719,\n",
       " 'da': 3500,\n",
       " 'hour': 6336,\n",
       " 'drinkbreak': 4098,\n",
       " 'ok': 9153,\n",
       " 'male': 7974,\n",
       " 'default': 3661,\n",
       " 'word': 13970,\n",
       " 'women': 13948,\n",
       " 'remov': 10489,\n",
       " 'houston': 6340,\n",
       " 'austin': 1398,\n",
       " '99': 782,\n",
       " 'wholesom': 13815,\n",
       " 'redskin': 10410,\n",
       " 'chang': 2696,\n",
       " 'name': 8695,\n",
       " 'two': 13050,\n",
       " 'stone': 11995,\n",
       " 'street': 12038,\n",
       " 'innoc': 6657,\n",
       " 'schoolgirl': 10984,\n",
       " 'minami': 8343,\n",
       " 'asaka': 1297,\n",
       " '180': 450,\n",
       " '160': 428,\n",
       " 'eaten': 4242,\n",
       " 'jay': 6872,\n",
       " 'ova': 9318,\n",
       " 'dead': 3607,\n",
       " '128079': 199,\n",
       " 'sox': 11739,\n",
       " 'playoff': 9768,\n",
       " 'redsox': 10411,\n",
       " 'mlb': 8393,\n",
       " 'toss': 12786,\n",
       " 'offic': 9123,\n",
       " 'trashbucketchalleng': 12850,\n",
       " 'politician': 9822,\n",
       " 'run': 10790,\n",
       " 'bought': 2113,\n",
       " 'sumblim': 12141,\n",
       " 'birthday': 1891,\n",
       " 'kinda': 7211,\n",
       " 'indiangiv': 6600,\n",
       " 'hope': 6300,\n",
       " 'disappoint': 3879,\n",
       " 'plan': 9740,\n",
       " 'indirectli': 6604,\n",
       " 'sometim': 11674,\n",
       " 'head': 5998,\n",
       " 'end': 4393,\n",
       " 'still': 11976,\n",
       " 'wear': 13644,\n",
       " 'ugg': 13089,\n",
       " 'weather': 13649,\n",
       " 'cuh': 3440,\n",
       " 'momma': 8444,\n",
       " 'said': 10847,\n",
       " 'wast': 13597,\n",
       " 'plzing': 9792,\n",
       " 'bum': 2345,\n",
       " 'dude': 4157,\n",
       " 'nowher': 9026,\n",
       " 'pregnant': 9944,\n",
       " 'mood': 8479,\n",
       " 'sum': 12139,\n",
       " 'fresh': 5115,\n",
       " 'platter': 9755,\n",
       " 'teamfluffnevabluff': 12396,\n",
       " 'ross': 10742,\n",
       " 'amber': 1094,\n",
       " 'rose': 10738,\n",
       " 'loyal': 7829,\n",
       " 'wiz': 13924,\n",
       " 'mind': 8344,\n",
       " 'thong': 12581,\n",
       " 'squirt': 11862,\n",
       " 'geyser': 5431,\n",
       " 'decent': 3633,\n",
       " 'meal': 8155,\n",
       " 'thirst': 12572,\n",
       " 'trap': 12843,\n",
       " 'otter': 9287,\n",
       " 'cool': 3220,\n",
       " 'pet': 9614,\n",
       " 'broke': 2237,\n",
       " 'boy': 2139,\n",
       " 'deion': 3681,\n",
       " 'releas': 10469,\n",
       " 'exclus': 4557,\n",
       " 'shower': 11311,\n",
       " 'trustisbroken': 12943,\n",
       " 'youtub': 14225,\n",
       " 'dyke': 4207,\n",
       " 'compliment': 3115,\n",
       " 'wonder': 13952,\n",
       " 'youu': 14226,\n",
       " 'leav': 7460,\n",
       " 'plasticass': 9752,\n",
       " 'mayb': 8120,\n",
       " 'drink': 4097,\n",
       " 'balanc': 1537,\n",
       " 'mari': 8040,\n",
       " 'jane': 6852,\n",
       " 'itslevelstoothisshit': 6791,\n",
       " 'charl': 2715,\n",
       " 'movi': 8546,\n",
       " 'shia': 11234,\n",
       " 'lebouf': 7463,\n",
       " 'charli': 2718,\n",
       " 'ryan': 10818,\n",
       " 'gosl': 5608,\n",
       " 'buddi': 2315,\n",
       " 'whynot': 13834,\n",
       " 'cut': 3480,\n",
       " 'grow': 5734,\n",
       " 'attent': 1377,\n",
       " 'yet': 14175,\n",
       " 'somebodi': 11668,\n",
       " 'wet': 13721,\n",
       " 'tonight': 12747,\n",
       " 'tongu': 12745,\n",
       " 'deez': 3659,\n",
       " 'g': 5278,\n",
       " 'lock': 7720,\n",
       " 'militari': 8326,\n",
       " 'stori': 12015,\n",
       " '128564': 347,\n",
       " 'comment': 3089,\n",
       " 'laugh': 7416,\n",
       " 'cheat': 2735,\n",
       " 'wetback': 13722,\n",
       " 'stupid': 12087,\n",
       " 'bullshit': 2342,\n",
       " 'monkey': 8462,\n",
       " 'human': 6377,\n",
       " 'bodi': 2024,\n",
       " 'peac': 9523,\n",
       " 'seren': 11114,\n",
       " 'suck': 12117,\n",
       " '2014': 502,\n",
       " 'awak': 1423,\n",
       " 'slumber': 11527,\n",
       " 'pick': 9665,\n",
       " 'avatar': 1413,\n",
       " 'press': 9962,\n",
       " 'anchor': 1139,\n",
       " 'raw': 10325,\n",
       " '128080': 200,\n",
       " 'fact': 4622,\n",
       " 'perci': 9577,\n",
       " 'harvin': 5957,\n",
       " 'sweat': 12224,\n",
       " '128524': 308,\n",
       " '128588': 365,\n",
       " 'mauri': 8109,\n",
       " '70': 715,\n",
       " 'expos': 4586,\n",
       " 'aye': 1446,\n",
       " 'lookin': 7757,\n",
       " 'sure': 12189,\n",
       " 'bigger': 1848,\n",
       " 'boyfriend': 2142,\n",
       " 'stick': 11971,\n",
       " 'theori': 12519,\n",
       " 'black': 1936,\n",
       " 'tast': 12355,\n",
       " 'strawberri': 12035,\n",
       " 'milk': 8329,\n",
       " 'accident': 841,\n",
       " 'ate': 1353,\n",
       " 'firefli': 4855,\n",
       " 'chew': 2770,\n",
       " 'found': 5049,\n",
       " 'shame': 11175,\n",
       " 'glow': 5517,\n",
       " 'wa': 13509,\n",
       " 'sesam': 11127,\n",
       " 'cal': 2468,\n",
       " 'giggl': 5452,\n",
       " 'stadium': 11878,\n",
       " 'yep': 14163,\n",
       " 'coach': 3000,\n",
       " 'uk': 13105,\n",
       " 'probabl': 10003,\n",
       " 'weari': 13647,\n",
       " 'ur': 13265,\n",
       " 'x2': 14063,\n",
       " 'fckn': 4731,\n",
       " 'ios8': 6736,\n",
       " 'gb': 5364,\n",
       " 'selfi': 11087,\n",
       " 'answer': 1181,\n",
       " 'holi': 6216,\n",
       " '4': 613,\n",
       " 'daddi': 3510,\n",
       " 'goe': 5551,\n",
       " 'condom': 3145,\n",
       " 'anyway': 1198,\n",
       " 'outta': 9313,\n",
       " 'clinic': 2960,\n",
       " 'denzi': 3725,\n",
       " 'broski': 2256,\n",
       " 'izzi': 6813,\n",
       " 'kaepernick': 7064,\n",
       " 'chirp': 2807,\n",
       " 'morn': 8496,\n",
       " 'patsgonnasubtweet': 9496,\n",
       " 'drop': 4115,\n",
       " 'stack': 11876,\n",
       " 'song': 11681,\n",
       " 'download': 4049,\n",
       " 'mixtap': 8389,\n",
       " 'ever': 4517,\n",
       " 'normal': 8990,\n",
       " 'play': 9756,\n",
       " 'horribl': 6312,\n",
       " 'trick': 12894,\n",
       " 'whiff': 13776,\n",
       " 'lmaooo': 7678,\n",
       " 'gasp': 5336,\n",
       " 'behind': 1724,\n",
       " 'wash': 13586,\n",
       " 'hood': 6276,\n",
       " 'bunch': 2358,\n",
       " 'term': 12452,\n",
       " 'seton': 11133,\n",
       " 'cathol': 2607,\n",
       " 'student': 12073,\n",
       " 'low': 7820,\n",
       " 'divis': 3927,\n",
       " 'footbal': 5001,\n",
       " 'uncl': 13142,\n",
       " 'tom': 12731,\n",
       " 'muhfucka': 8580,\n",
       " 'doodl': 4011,\n",
       " 'farm': 4688,\n",
       " 'cotton': 3265,\n",
       " 'support': 12184,\n",
       " 'idk': 6465,\n",
       " 'though': 12592,\n",
       " 'also': 1072,\n",
       " 'betdat': 1797,\n",
       " 'dear': 3617,\n",
       " 'spoil': 11815,\n",
       " 'suburban': 12110,\n",
       " 'leg': 7485,\n",
       " 'hippo': 6165,\n",
       " 'tommi': 12737,\n",
       " 'voeckler': 13473,\n",
       " 'andi': 1142,\n",
       " 'schleck': 10972,\n",
       " 'tour': 12800,\n",
       " 'contador': 3188,\n",
       " 'broken': 2240,\n",
       " 'incred': 6590,\n",
       " 'tdf': 12383,\n",
       " 'reason': 10360,\n",
       " 'school': 10981,\n",
       " 'hard': 5934,\n",
       " 'ned': 8769,\n",
       " 'guid': 5766,\n",
       " 'anyth': 1195,\n",
       " '8th': 755,\n",
       " 'unattract': 13131,\n",
       " 'bestsongtohavesexto': 1790,\n",
       " 'sosa': 11715,\n",
       " 'bangbang': 1574,\n",
       " 'loyalll': 7831,\n",
       " 'burnt': 2379,\n",
       " 'nicca': 8849,\n",
       " 'overus': 9351,\n",
       " 'excus': 4558,\n",
       " 'lyric': 7887,\n",
       " 'men': 8212,\n",
       " 'vice': 13401,\n",
       " 'versa': 13383,\n",
       " 'rat': 10309,\n",
       " 'rememb': 10484,\n",
       " 'halo': 5882,\n",
       " 'episod': 4447,\n",
       " 'finish': 4843,\n",
       " 'chapter': 2707,\n",
       " 'without': 13917,\n",
       " 'disappear': 3878,\n",
       " 'retweet': 10560,\n",
       " 'random': 10282,\n",
       " 'kirk': 7224,\n",
       " 'hiphop': 6162,\n",
       " 'popcorn': 9852,\n",
       " 'bol': 2036,\n",
       " 'cheer': 2747,\n",
       " 'alex': 1017,\n",
       " 'smith': 11567,\n",
       " 'ofcours': 9118,\n",
       " 'jackass': 6820,\n",
       " 'surpris': 12195,\n",
       " 'dingbat': 3849,\n",
       " 'bffl': 1821,\n",
       " 'solo': 11661,\n",
       " 'tbt': 12375,\n",
       " 'learn': 7453,\n",
       " 'english': 4413,\n",
       " 'jabroni': 6817,\n",
       " 'kind': 7210,\n",
       " 'world': 13981,\n",
       " 'surgeri': 12194,\n",
       " 'butt': 2404,\n",
       " 'lmfaooooo': 7696,\n",
       " 'gt': 5746,\n",
       " 'lmaoo': 7677,\n",
       " 'dougi': 4041,\n",
       " 'yam': 14104,\n",
       " 'coon': 3227,\n",
       " 'box': 2137,\n",
       " 'respect': 10532,\n",
       " 'ewh': 4542,\n",
       " 'inbr': 6574,\n",
       " 'crusti': 3411,\n",
       " 'trippin': 12915,\n",
       " 'ion': 6732,\n",
       " 'drippin': 4103,\n",
       " 'singl': 11395,\n",
       " 'wasp': 13592,\n",
       " 'read': 10339,\n",
       " 'waspfact': 13593,\n",
       " 'treati': 12873,\n",
       " 'ahhh': 968,\n",
       " 'maaaaannnn': 7898,\n",
       " 'rid': 10607,\n",
       " 'john': 6975,\n",
       " 'legend': 7488,\n",
       " 'batch': 1639,\n",
       " 'chillin': 2790,\n",
       " 'fuckin': 5190,\n",
       " 'enough': 4422,\n",
       " 'drain': 4068,\n",
       " 'idkmadz': 6466,\n",
       " 'tbh': 12373,\n",
       " 'seen': 11078,\n",
       " 'recess': 10383,\n",
       " 'busi': 2389,\n",
       " 'rate': 10313,\n",
       " 'finna': 4846,\n",
       " 'knew': 7247,\n",
       " 'wassup': 13596,\n",
       " 'hide': 6124,\n",
       " 'obviou': 9097,\n",
       " 'walk': 13549,\n",
       " 'countri': 3283,\n",
       " 'kitchen': 7229,\n",
       " 'restaur': 10539,\n",
       " 'order': 9252,\n",
       " 'tabl': 12281,\n",
       " 'lone': 7741,\n",
       " 'roll': 10709,\n",
       " '103': 23,\n",
       " 'b': 1466,\n",
       " 'remind': 10486,\n",
       " 'b4': 1469,\n",
       " 'di': 3792,\n",
       " 'social': 11635,\n",
       " 'network': 8804,\n",
       " 'fame': 4664,\n",
       " '128539': 322,\n",
       " '128570': 352,\n",
       " ...}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @FunSizedYogi: @TheBlackVoice well how else will white ppl get us to forget our horrific past other than to paint a pretty picture of ho&#8230;',\n",
       "       \"Funny thing is....it's not just the people doing it. It's the people who seeing these pics and judging the birds. Just as wrong.\",\n",
       "       'RT @winkSOSA: \"@AintShitSweet__: \"@Rakwon_OGOD: Nigga messed with the wrong bitch &#128557;&#128514;https://t.co/5mNXKVAYot\" &#128557;&#128557;&#128557;&#128557;&#128514;&#128514;&#128557;&#128557;&#128514;&#128514;&#128514;&#128514;&#128514;&#128514;&#128514;\"@Th_Real_Esco',\n",
       "       ...,\n",
       "       '#porn,#android,#iphone,#ipad,#sex,#xxx, | #Anal | Hardcore british queer anal pounding http://t.co/lRuEixMy21',\n",
       "       \"RT @JennyJohnsonHi5: Just when I thought Justin Bieber couldn't be anymore of a pussy, he gets arrested in Canada for fighting a person who&#8230;\",\n",
       "       'bitches ain&#8217;t shit, and they ain&#8217;t saying nothin&#8217;'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "#     ('vectorizer', count_vectorizer),\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.values, y_train.values);\n",
    "dump(pipeline, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"hi\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=5)\n",
    "scores = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "probas = []\n",
    "confusion = np.array([[0, 0], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indices, test_indices in k_fold.split(counts):\n",
    "    train_text = df.iloc[train_indices]['tweet']\n",
    "    train_y = df.iloc[train_indices]['isHateSpeech']\n",
    "\n",
    "    test_text = df.iloc[test_indices]['tweet']\n",
    "    test_y = df.iloc[test_indices]['isHateSpeech']\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "    prediction_probas = pipeline.predict_proba(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = accuracy_score(test_y, predictions)\n",
    "    scores.append(score)\n",
    "    \n",
    "    y_true.extend(test_y)\n",
    "    y_pred.extend(predictions.tolist())\n",
    "    probas.extend(prediction_probas[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets classified: 24783\n",
      "Accuracy: 0.8526180478582452\n",
      "Confusion matrix:\n",
      "[[  692   504]\n",
      " [ 2418 16212]]\n"
     ]
    }
   ],
   "source": [
    "print('Total tweets classified:', len(df))\n",
    "print('Accuracy:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "- Model is predicting hate speech based on keyword only -> context is not considered\n",
    "- Lack of hate speech data -> resampling, StratifiedKFold, SMOTE\n",
    "- Synthesisis of new minority class instances\n",
    "- Over-sampling of minority class\n",
    "- Under-sampling of majority class\n",
    "- Tweak the cost function to make misclassification of minority instances more important than misclassification of majority instances\n",
    "\n",
    "\n",
    "### Metrics\n",
    "- False positive should be minimized\n",
    "- Macro average in classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"gay\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1196\n",
      "           1       0.94      1.00      0.97     18630\n",
      "\n",
      "    accuracy                           0.94     19826\n",
      "   macro avg       0.47      0.50      0.48     19826\n",
      "weighted avg       0.88      0.94      0.91     19826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qa/Documents/Github/cs6220-data-mining/hate-speech-identifer/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qa/Documents/Github/cs6220-data-mining/hate-speech-identifer/env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:572: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  y_true = (y_true == pos_label)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-a9c6fa329241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute ROC curve and ROC area for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/cs6220-data-mining/hate-speech-identifer/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/cs6220-data-mining/hate-speech-identifer/env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[0;32m--> 775\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    776\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/cs6220-data-mining/hate-speech-identifer/env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mdesc_score_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mergesort\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_true, probas, pos_label='spam')\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
